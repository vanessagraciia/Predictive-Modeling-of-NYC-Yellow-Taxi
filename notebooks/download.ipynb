{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/20 23:00:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library needed\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "# from the current `scripts` directory, go back one level to the `MAST30034-project-1` landing directory \n",
    "output_relative_dir = '../data/landing/'\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    \n",
    "# now, for each type of data set we will need, we will create the paths\n",
    "for target_dir in ('taxi_data', 'weather', 'geopandas'): \n",
    "    if not os.path.exists(output_relative_dir + target_dir):\n",
    "        os.makedirs(output_relative_dir + target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the URL template for yellow taxi data\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"#year-month.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin year 2022 month 01\n",
      "Completed year 2022 month 01\n",
      "Begin year 2022 month 02\n",
      "Completed year 2022 month 02\n",
      "Begin year 2022 month 03\n",
      "Completed year 2022 month 03\n",
      "Begin year 2022 month 04\n",
      "Completed year 2022 month 04\n",
      "Begin year 2022 month 05\n",
      "Completed year 2022 month 05\n",
      "Begin year 2022 month 06\n",
      "Completed year 2022 month 06\n",
      "Begin year 2022 month 07\n",
      "Completed year 2022 month 07\n",
      "Begin year 2022 month 08\n",
      "Completed year 2022 month 08\n",
      "Begin year 2022 month 09\n",
      "Completed year 2022 month 09\n",
      "Begin year 2022 month 10\n",
      "Completed year 2022 month 10\n",
      "Begin year 2022 month 11\n",
      "Completed year 2022 month 11\n",
      "Begin year 2022 month 12\n",
      "Completed year 2022 month 12\n",
      "Begin year 2023 month 02\n",
      "Completed year 2023 month 02\n"
     ]
    }
   ],
   "source": [
    "# data output directory is `data/landing/`\n",
    "tlc_output_dir = output_relative_dir + 'taxi_data'\n",
    "\n",
    "for year in range(2022, 2024):\n",
    "    if year == 2022:\n",
    "        MONTH = range(1, 13)\n",
    "    if year == 2023:\n",
    "        MONTH = range(2, 3)\n",
    "\n",
    "    for month in MONTH: \n",
    "        month = str(month).zfill(2) \n",
    "        print(f\"Begin year {year} month {month}\")\n",
    "    \n",
    "        # generate url\n",
    "        url = f'{URL_TEMPLATE}{str(year)}-{month}.parquet'\n",
    "        # generate output location and filename\n",
    "        output_dir = f\"{tlc_output_dir}/{str(year)}-{month}.parquet\"\n",
    "        # download\n",
    "        urlretrieve(url, output_dir) \n",
    "\n",
    "        print(f\"Completed year {year} month {month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/landing/weather/2022.csv',\n",
       " <http.client.HTTPMessage at 0x7fa768720a60>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This code is for downloading weather data from Visual Crossing website '''\n",
    "\n",
    "weather_output_dir = output_relative_dir + 'weather'\n",
    "\n",
    "# this is the URL for weather\n",
    "url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/new%20york%20city/2021-12-31/2022-12-31?unitGroup=metric&elements=datetime%2CdatetimeEpoch%2Ctemp%2Cprecip%2Csnow%2Cwindspeed%2Cconditions&include=hours&key=5R8VYKM4X9FTJD8GPHGNTHUNE&contentType=csv\"\n",
    "urlretrieve(url, f'{weather_output_dir}/2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/landing/geopandas/taxi_shapefile.zip',\n",
       " <http.client.HTTPMessage at 0x7fa76870bdc0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This code is for downloading shapefile data from tlc website '''\n",
    "\n",
    "shapefile_output_dir = output_relative_dir + 'geopandas'\n",
    "\n",
    "# this is the URL for shapefile \n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "url2 = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip\"\n",
    "\n",
    "urlretrieve(url, f'{shapefile_output_dir}/taxi_zones.csv')\n",
    "urlretrieve(url2, f'{shapefile_output_dir}/taxi_shapefile.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 23:02:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "''' This code is to extract the zipfile downloaded, this is to access the shapefile\n",
    "model inside the zipfile ''' \n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"UnzipShapefile\").getOrCreate()\n",
    "\n",
    "# Specify paths\n",
    "zip_file_path = \"../data/landing/geopandas/taxi_shapefile.zip\"\n",
    "extracted_dir = \"../data/landing/geopandas/\"\n",
    "\n",
    "# Create the DataFrame with the binary data of the zip file\n",
    "df = spark.read.format(\"binaryFile\").load(zip_file_path)\n",
    "\n",
    "# Convert the binary data to a bytearray\n",
    "byte_array = bytearray(df.select(\"content\").first()[0])\n",
    "\n",
    "# Convert the bytearray to a BytesIO stream\n",
    "byte_stream = BytesIO(byte_array)\n",
    "\n",
    "# Extract the zip contents to the specified directory\n",
    "with zipfile.ZipFile(byte_stream, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
